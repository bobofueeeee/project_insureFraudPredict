计划

1. 重新整个项目，得分高于0.95分
2. 加入eda分析
3. 加入画图
4. 加入网格调参
5. 加入模型的交叉验证:https://blog.csdn.net/weixin_42060598/article/details/132180213
6. 最后评估一下指标，为什么跟分数不匹配，可以得出指标和各个参数的趋势图不



## 数据挖掘中用到了哪些统计学知识

```
在数据挖掘中，会用到哪些统计学知识？

在数据挖掘中，会广泛运用到多种统计学知识。以下是一些主要的应用方面：
描述性统计：数据挖掘经常需要描述数据的特征，这时就会用到描述性统计的知识。比如，通过计算均值、中位数、众数、方差和标准差等统计量，可以了解数据的集中趋势和离散程度。

概率论：概率论在数据挖掘中扮演着重要角色。它提供了理解和量化不确定性的工具，帮助研究者评估数据的可能性和风险。例如，在分类问题中，概率论可以用于计算一个样本属于某个类别的概率。

假设检验：假设检验是统计学中一种重要的方法，用于根据样本数据对总体参数进行推断。在数据挖掘中，经常需要验证某个假设是否成立，比如某个特征是否与目标变量有显著关系。

回归分析：回归分析是探究变量之间关系的一种统计学方法。在数据挖掘中，回归分析常用于预测和解释，例如预测一个连续变量的值，或者解释一个变量如何影响另一个变量。

方差分析：方差分析用于比较不同来源的变异对总变异的贡献大小，从而确定可控因素对研究结果影响力的大小。在数据挖掘中，方差分析可以帮助我们理解不同特征或因素对目标变量的影响程度。

聚类分析：聚类分析是一种无监督学习方法，用于将数据集中的对象分成若干个类或簇，使得同一类内的对象相似度高，不同类之间的相似度低。这涉及到统计学中的距离计算和相似度度量等知识。

时间序列分析：对于具有时间序列特性的数据，需要用到时间序列分析的知识。通过时间序列分析，可以揭示数据随时间变化的规律和趋势，进而进行预测和决策。

综上所述，数据挖掘中运用到的统计学知识非常广泛，这些统计学方法和技术为数据挖掘提供了强大的支持，使得我们可以从大量数据中提取有用的信息和知识。
```

### 描述性统计

```
数据的集中趋势和离散程度，对数据挖掘有什么帮助吗？

数据的集中趋势和离散程度在数据挖掘中确实具有重要的作用，它们为分析提供了关键的洞察，帮助研究者更好地理解和处理数据。以下是具体的几个方面：

数据描述与理解：
集中趋势（如均值、中位数）描述了数据的“中心”位置，有助于我们快速了解数据的整体水平和典型值。
离散程度（如方差、标准差）则反映了数据的波动性和分布情况，帮助我们了解数据的稳定性和差异性。

特征选择与重要性评估：
在特征选择过程中，集中趋势和离散程度可以帮助我们识别出那些对目标变量影响较大的特征。例如，如果一个特征的离散程度很高，那么它可能对目标变量的预测能力较强。
通过比较不同特征的集中趋势和离散程度，我们可以评估它们的重要性，从而选择出最有代表性的特征进行后续分析。

异常值检测：
离散程度的度量可以帮助我们识别数据中的异常值或极端值。这些值可能是由于数据录入错误、测量误差或其他原因导致的，它们可能会对数据挖掘的结果产生负面影响。
通过比较一个数据点与整体数据的集中趋势和离散程度，我们可以判断它是否为异常值，并进行相应的处理。

模型选择与调优：
在选择数据挖掘模型时，了解数据的集中趋势和离散程度可以帮助我们选择合适的模型类型和参数设置。
例如，在构建线性回归模型时，如果数据的离散程度很大，可能需要考虑使用更稳健的回归方法或进行特征缩放以减小不同特征之间的量纲差异。

结果解释与可视化：
集中趋势和离散程度可以作为数据挖掘结果解释的重要依据。通过比较不同组或类别的数据的集中趋势和离散程度，我们可以揭示它们之间的差异和联系。
此外，这些统计量还可以用于数据可视化，帮助研究者更直观地展示数据的分布和特征。

综上所述，数据的集中趋势和离散程度在数据挖掘中扮演着重要的角色，它们为我们提供了对数据的基本认识和深入分析的基础。
```

```python
## 1.异常值，可能是坏样本的特征
## 2.数据的离散程度很大，可能需要考虑使用更稳健的回归方法或进行特征缩放以减小不同特征之间的量纲差异。
## 3. 例如，如果一个特征的离散程度很高，那么它可能对目标变量的预测能力较强。
```

### 假设检验

```python
## 1. 假设某个变量不重要，就剔除掉，看对模型的影响大不大，不大，则不重要
```

### 回归分析

```python
## 回归分析（如Lasso回归和逐步回归分析）可以帮助我们识别并选择与目标变量最相关的特征，从而提高分类模型的性能。
```

### 交叉验证

```
交叉验证（Cross-Validation）则主要用于建模应用中，如主成分回归（PCR）和偏最小二乘（PLS）回归建模等。
它尤其适用于数据不是很充足的情况。交叉验证的基本思想是将原始数据分成训练集、验证集和测试集，用训练集来训练模型，用验证集来评估模型的好坏和选择模型及其对应的参数，最后用测试集来最终决定使用哪个模型以及对应的参数。
这样做可以有效地评估模型的预测性能，尤其是模型在新数据上的表现，并在一定程度上减少过拟合的风险。
```

#### 简单交叉验证

```python
## 1. 简单交叉验证,使用learn库中的train_test_split
from sklearn.model_selection import train_test_split  
from sklearn.linear_model import LinearRegression  
from sklearn import metrics  
import numpy as np  
  
# 假设 X 是特征数据，y 是目标变量  
# 这里我们创建一些模拟数据作为示例  
X = np.random.rand(100, 5)  # 100个样本，每个样本5个特征  
y = np.dot(X, np.array([1, 2, 3, 4, 5])) + 30  # 线性关系加上一些噪声  
  
# 将数据分为训练集和测试集，通常测试集占20%-30%  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  
  
# 创建并训练模型  
model = LinearRegression()  
model.fit(X_train, y_train)  
  
# 使用测试集进行预测  
y_pred = model.predict(X_test)  
  
# 评估模型性能  
mse = metrics.mean_squared_error(y_test, y_pred)  
print(f'Mean Squared Error: {mse}')

# random_state参数用于确保每次分割数据时得到相同的结果，这在重复实验或调试时非常有用。在实际应用中，你可能还需要进行超参数调整、模型选择等其他步骤来进一步优化模型的性能。
```

#### K折交叉验证

```python
# 2.0 K折交叉验证cross_val_score
# 在Python中，K折交叉验证（K-fold Cross-validation）可以通过sklearn.model_selection模块中的KFold或cross_val_score函数来实现。以下是使用cross_val_score函数进行K折交叉验证的示例代码：
from sklearn.model_selection import cross_val_score  
from sklearn.linear_model import LinearRegression  
import numpy as np  
  
# 假设 X 是特征数据，y 是目标变量  
# 这里我们创建一些模拟数据作为示例  
X = np.random.rand(100, 5)  # 100个样本，每个样本5个特征  
y = np.dot(X, np.array([1, 2, 3, 4, 5])) + 30  # 线性关系加上一些噪声  
  
# 创建一个线性回归模型  
model = LinearRegression()  
  
# 使用 cross_val_score 进行 5 折交叉验证  
# cv 参数指定了折数  
scores = cross_val_score(model, X, y, cv=5)  
  
# 输出每一折的分数和平均分数  
print("Scores for each fold:", scores)  
print("Mean cross-validation score:", scores.mean())
```

```python
# 2.1 KFold类
# 如果你想要更精细地控制数据集的分割，你可以使用KFold类来手动创建折，并在这些折上循环进行训练和评估。以下是一个使用KFold类的示例：
from sklearn.model_selection import KFold  
from sklearn.linear_model import LinearRegression  
from sklearn.metrics import mean_squared_error  
import numpy as np  
  
# 假设 X 是特征数据，y 是目标变量  
# ...（同上）  
  
# 创建一个 KFold 对象，这里 k=5  
kf = KFold(n_splits=5, shuffle=True, random_state=42)  
  
# 初始化模型  
model = LinearRegression()  
  
# 初始化一个列表来存储每一折的分数  
scores = []  
  
# 对每一折进行训练和评估  
for train_index, test_index in kf.split(X):  
    X_train, X_test = X[train_index], X[test_index]  
    y_train, y_test = y[train_index], y[test_index]  
      
    # 训练模型  
    model.fit(X_train, y_train)  
      
    # 预测  
    y_pred = model.predict(X_test)  
      
    # 计算并存储分数（这里使用均方误差的负值作为分数，因为 scikit-learn 的 cross_val_score 默认是越高越好）  
    score = -mean_squared_error(y_test, y_pred)  
    scores.append(score)  
  
# 输出每一折的分数和平均分数  
print("Scores for each fold:", scores)  
print("Mean cross-validation score:", np.mean(scores))
```

#### cross_validate 和 cross_val_score有什么区别

```
cross_validate和cross_val_score在scikit-learn库中都是用于交叉验证的工具，但它们之间存在一些关键的区别。

功能：

cross_val_score：主要用于评估模型的预测性能，它返回每次验证迭代的分数，并且默认情况下返回的是模型的精度（accuracy）。这个函数主要用于分类和回归问题，并返回每个分割的得分。
cross_validate：除了评估模型的预测性能外，它还可以返回更多的评估指标，如训练得分、拟合时间等。此外，它还可以返回测试集上的多个评分，例如，对于分类任务，它可以返回精度、召回率、F1得分等。
返回结果：

cross_val_score：返回一个数组，其中包含了每次验证迭代的得分。
cross_validate：返回一个字典，其中包含了多个评估指标，如test_score（测试集上的得分）、train_score（训练集上的得分）、fit_time（模型拟合时间）等。
使用场景：

如果你主要关心模型的预测性能，并且只需要一个主要的评估指标（如精度），那么cross_val_score可能是更简单的选择。
如果你需要更全面的评估模型，包括多个评估指标和训练/测试得分，那么cross_validate可能更适合你。
总的来说，cross_validate提供了比cross_val_score更全面的评估，但如果你只需要一个简单的预测性能评估，那么cross_val_score可能更简洁和直接。
```



### 当面对连续变量时，Bagging 和 Boosting算法哪种比较适合

```
当面对连续变量时，Bagging和Boosting算法都可以使用，但具体哪种更适合取决于数据的特性、问题的需求以及模型的性能要求。

Bagging算法（Bootstrap Aggregating）倾向于使用偏差低、方差高的模型作为基学习器，如决策树。它通过从原始样本集中抽取训练集来增加样本扰动，并增强融合后模型的泛化能力，降低方差。Bagging不侧重于训练数据集中的任何特定实例，因为每个样本被选中的概率相同。它的性能依赖于基分类器的稳定性，对于不稳定的基学习器，Bagging有助于降低训练数据的随机波动导致的误差，增强了稳定性和泛化能力。

而Boosting算法则通过自适应的方式顺序地学习弱学习器，每个新学习器都依赖于前面的模型，并按照某种确定性的策略将它们组合起来。AdaBoost和Gradient Boosting是两种重要的Boosting算法。Boosting采用顺序的方式最小化损失函数，所以偏差通常是逐步下降的。但是，子模型之和可能不能显著降低方差。

对于连续变量，如果数据集的分布较为均匀，没有明显的异常值或噪声，且希望得到一个稳定且泛化能力强的模型，那么Bagging可能是一个不错的选择。但如果数据集中存在较大的噪声或异常值，或者希望模型能够逐步减少偏差，那么Boosting可能更适合。

总的来说，选择Bagging还是Boosting取决于具体的应用场景和数据特性。在实际应用中，可以通过交叉验证等方法来评估不同算法的性能，从而选择最适合的算法。
```

### 总结⭐

```shell
## 数据挖掘步骤
# 1. 数据概况
# 1.1 空值、异常值等等，决定作怎样的数据清洗
# 1.2 数据类型，应该做怎样的转换、编码
# 1.3 分布范围，离散、连续、异常值多少等等，适合怎样的模型（随机森林对异常值不敏感，因为会平均投票；梯度下降对异常值敏感，因为是感知器的迭代，容易过拟合）

# 2. 数据清洗
# 主要对空值填充

# 3. 数据编码
# 3.1 对字符类型的转换编码（机器学习模型不读字符）
# 3.2 先分箱，再进行woe值编码（金融风控）
# 3.3 对十个离散型以上的进行均值编码（减少连续性变量）

# 4. 特征选择
# 4.1 根据相关性、iv值，剔除无关的特征
# 4.2 根据特征重要度，逐一排除特征，看对模型有无影响


# 5. 模型选择
# 5.1 线性回归
# 5.2 逻辑回归
# 5.3 决策树
# 5.3 随机森林
# 5.4 向量机
# 5.5 XGboost
# 5.6 lightGBM
# 5.7 GBDT模型

# 5.8 模型训练的原理
# 基于损失函数(计算预测值与真实值的差距，例如求误差的平方)，减少损失值(误差)的过程
# 模型训练中，基于损失函数，有很多的优化方法
# 1）梯度下降：将损失函数中的预测值转换wx+b，w代表权重，b代表偏置，得到类似 误差 = wx+b - 实际值的损失函数，并对此求导数，得到梯度，找到最小的梯度点，反向推出它的w，b,并以此对模型进行优化，再训练
# 2）正则化：正则化的目的是防止过拟合，也是基于损失函数，加入惩罚机制，假设 预测值=wx+b w代表权重，b代表偏置, 加入一个收缩系数α(负值) ， 预测值 = αwx+b,误差 = αwx+b - 实际值, 如果收缩系数α不断减小，-1变到-10，但是误差没有变化，就说明这个特征x不重要，可以考虑舍弃，从而避免过拟合。具体的岭回归、lasso回归、和弹性网络可以参考下两图，岭回归在于系数αw无限趋近于0，而lasso回归可以为为0，但曲线陡峭不平滑，弹性网络结合岭回归、lasso回归的特点，系数可以为0，且曲线平滑

# 综上，在模型调优中，例如xgboost模型，可以对损失函数、正则化进行调整，主要通过超参数调整，例如loss=logloss，使用对数损失函数；因为自带了梯度下降算法，所以不同对此进行调整

# 6. 模型调优
# 6.1 网格调参(超参数调整：学习率、批次、最大深度、损失函数、正则化等)
# 6.2 特征逐一排除(可以手动，一个一个剔除，观察对模型评分的影响，有些模型也自带正则化参数，能在训练时自动剔除，最后我们通过查看模型的特征重要度，来反向进行特特征的筛选)


# 7. 模型评估
# 7.1 交叉验证
# 7.1.1 通过调整train_test_split的，test_size参数，观察auc值的极限，如果auc变化趋势不明显，则应找到临界点，防止过拟合
# 7.1.2 利用cross_validate，进行K折交叉验证，观察不同模型模型的指标，进行评估
# 7.1.3 利用KFold类，对样本进行拆分，每一次分割的指标的平均值，加强模型评估的准确性
## 所以，交叉验证一是找到auc的临界点，二是对比各个模型的评估指标

# 7.2 常规指标评估
# 精确性、准确性、f1值、auc值、roc曲线、指标的重要程度

```

![image-20240430123942588](https://gitee.com/fubob/note-pic/raw/master/image/image-20240430123942588.png)

![image-20240430124043710](https://gitee.com/fubob/note-pic/raw/master/image/image-20240430124043710.png)

### 思考⭐

```shell
## 在数据挖掘中，对最后模型质量的影响比较重要的几点
## 1. 数据本身，包括对数据的清洗，数据的降维(特征的选择)，数值的组合、衍生，数据编码
## 1.1 数据清洗，主要对空值的处理，格式不对的处理
## 1.2 数值编码，例如对字符进行转换，对数值进行分箱，在woe编码
## 1.3 数据的降维(特征的选择)，基于相关性、iv值、分布情况等进行特征选择
## 1.4 数值的组合、衍生，基于对数据分布、eda的探索理解，对数据进行衍生或者在组合

# 2. 模型的选择，结合各个模型的特点，与数据本身的情况，选择合适的模型
## 有几点要求，一是理解常见算法的原理， 二是理解常见算法适用怎样的数据，和需求，三是理解模型训练中，优化的原理

# 3. 超参数的调优,(学习率、批次、最大深度、损失函数、正则化等)调整
# 利用贪心算法、网格调参、贝叶斯调参,进行(学习率、批次、最大深度、损失函数、正则化等)调整，特别时类似xgboost模型，对最后模型的评分影响较大

# 4. 模型评估,利用交叉验证、常见指标评估，评估模型质量
# 4.1 交叉验证
# 4.1.1 通过调整train_test_split的，test_size参数，观察auc值的极限，如果auc变化趋势不明显，则应找到临界点，防止过拟合
# 4.1.2 利用cross_validate，进行K折交叉验证，观察不同模型模型的指标，进行评估
# 4.1.3 利用KFold类，对样本进行拆分，每一次分割的指标的平均值，加强模型评估的准确性
## 所以，交叉验证一是找到auc的临界点，二是对比各个模型的评估指标

# 4.2 精确性、准确性、f1值、auc值、roc曲线、指标的重要程度

# 在实际操作过程中，对模型影响较大的因素
# 1）数据本身 ⭐⭐  对日期的处理，从0.89提升到0.92
# 2）模型选择 ⭐⭐  选择xgboost模型，从0.85提升到0.89
# 3）超参数
# 4）训练集的划分比例，避免过拟合 + ⭐⭐ 模型融合，在划分阶段，对k中，每一次样本预测的结果总和求平均 从0.92提升到0.95
```

